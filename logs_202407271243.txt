Use GPU: 0 for training
=> creating model 'resnet50'
DetectionCL(
  (encoder_q): Sequential(
    (0): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (1): MlpHead(
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (mlp): Sequential(
        (0): Linear(in_features=2048, out_features=2048, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=2048, out_features=128, bias=True)
      )
    )
    (2): Yolov8Head(
      (up1): Upsample(scale_factor=2.0, mode=nearest)
      (c2f_1): C2f(
        (cv1): Conv(
          (conv): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (m): ModuleList(
          (0): Bottleneck(
            (cv1): Conv(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
            (cv2): Conv(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
          )
        )
      )
      (up2): Upsample(scale_factor=2.0, mode=nearest)
      (c2f_2): C2f(
        (cv1): Conv(
          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (m): ModuleList(
          (0): Bottleneck(
            (cv1): Conv(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
            (cv2): Conv(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
          )
        )
      )
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (c2f_3): C2f(
        (cv1): Conv(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (m): ModuleList(
          (0): Bottleneck(
            (cv1): Conv(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
            (cv2): Conv(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
          )
        )
      )
      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (c2f_4): C2f(
        (cv1): Conv(
          (conv): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (m): ModuleList(
          (0): Bottleneck(
            (cv1): Conv(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
            (cv2): Conv(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
          )
        )
      )
      (conv_fuse): Conv2d(1792, 1024, kernel_size=(1, 1), stride=(1, 1))
      (bn_fuse): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu_fuse): ReLU(inplace=True)
    )
  )
  (encoder_k): Sequential(
    (0): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (1): MlpHead(
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (mlp): Sequential(
        (0): Linear(in_features=2048, out_features=2048, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=2048, out_features=128, bias=True)
      )
    )
    (2): Yolov8Head(
      (up1): Upsample(scale_factor=2.0, mode=nearest)
      (c2f_1): C2f(
        (cv1): Conv(
          (conv): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (m): ModuleList(
          (0): Bottleneck(
            (cv1): Conv(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
            (cv2): Conv(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
          )
        )
      )
      (up2): Upsample(scale_factor=2.0, mode=nearest)
      (c2f_2): C2f(
        (cv1): Conv(
          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (m): ModuleList(
          (0): Bottleneck(
            (cv1): Conv(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
            (cv2): Conv(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
          )
        )
      )
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (c2f_3): C2f(
        (cv1): Conv(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (m): ModuleList(
          (0): Bottleneck(
            (cv1): Conv(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
            (cv2): Conv(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
          )
        )
      )
      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (c2f_4): C2f(
        (cv1): Conv(
          (conv): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (cv2): Conv(
          (conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): SiLU()
        )
        (m): ModuleList(
          (0): Bottleneck(
            (cv1): Conv(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
            (cv2): Conv(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): SiLU()
            )
          )
        )
      )
      (conv_fuse): Conv2d(1792, 1024, kernel_size=(1, 1), stride=(1, 1))
      (bn_fuse): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu_fuse): ReLU(inplace=True)
    )
  )
)
Epoch: [0][  0/464]	Time 12.030 (12.030)	Data  6.416 ( 6.416)	Loss 5.0323e-01 (5.0323e-01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst 100.00 (100.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [0][100/464]	Time  0.089 ( 0.204)	Data  0.000 ( 0.064)	Loss 4.1247e+01 (1.5361e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 26.73)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [0][200/464]	Time  0.090 ( 0.145)	Data  0.000 ( 0.033)	Loss 1.9176e+02 (5.8579e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 26.24)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [0][300/464]	Time  0.087 ( 0.126)	Data  0.000 ( 0.022)	Loss 2.5446e+01 (5.5166e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.42)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [0][400/464]	Time  0.091 ( 0.116)	Data  0.000 ( 0.017)	Loss 4.2337e+01 (4.7828e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 25.69)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [1][  0/464]	Time 13.335 (13.335)	Data 13.242 (13.242)	Loss 1.1695e+02 (1.1695e+02)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 50.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [1][100/464]	Time  0.084 ( 0.219)	Data  0.000 ( 0.132)	Loss 1.7617e+01 (5.1766e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 23.76)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [1][200/464]	Time  0.083 ( 0.152)	Data  0.000 ( 0.067)	Loss 3.4443e+01 (3.8966e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 24.25)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [1][300/464]	Time  0.091 ( 0.131)	Data  0.000 ( 0.045)	Loss 7.0344e+01 (4.2594e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 22.92)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [1][400/464]	Time  0.081 ( 0.120)	Data  0.000 ( 0.034)	Loss 5.5169e+01 (4.6869e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 23.19)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [2][  0/464]	Time  6.463 ( 6.463)	Data  6.148 ( 6.148)	Loss 1.8235e+01 (1.8235e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [2][100/464]	Time  0.088 ( 0.148)	Data  0.000 ( 0.061)	Loss 8.4219e+00 (2.1717e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.50)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [2][200/464]	Time  0.100 ( 0.117)	Data  0.000 ( 0.031)	Loss 6.9639e+00 (1.4514e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 23.01)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [2][300/464]	Time  0.086 ( 0.107)	Data  0.000 ( 0.021)	Loss 1.0952e+02 (2.1402e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 23.50)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [2][400/464]	Time  0.087 ( 0.102)	Data  0.000 ( 0.016)	Loss 1.5260e+01 (3.3521e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 22.26)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [3][  0/464]	Time  6.960 ( 6.960)	Data  6.576 ( 6.576)	Loss 5.8588e+00 (5.8588e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [3][100/464]	Time  0.082 ( 0.154)	Data  0.000 ( 0.066)	Loss 4.6447e+00 (5.3652e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.79)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [3][200/464]	Time  0.083 ( 0.120)	Data  0.000 ( 0.033)	Loss 4.5330e+00 (4.9445e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.52)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [3][300/464]	Time  0.083 ( 0.109)	Data  0.000 ( 0.022)	Loss 4.1800e+00 (4.8755e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 21.26)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [3][400/464]	Time  0.083 ( 0.103)	Data  0.000 ( 0.017)	Loss 6.3612e+01 (5.7960e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 21.51)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [4][  0/464]	Time  6.546 ( 6.546)	Data  6.296 ( 6.296)	Loss 4.8273e+00 (4.8273e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [4][100/464]	Time  0.084 ( 0.152)	Data  0.000 ( 0.063)	Loss 1.3705e+01 (7.8122e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 26.49)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [4][200/464]	Time  0.081 ( 0.120)	Data  0.000 ( 0.032)	Loss 5.0710e+00 (4.3751e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.89)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [4][300/464]	Time  0.077 ( 0.110)	Data  0.000 ( 0.021)	Loss 5.7199e+00 (3.2246e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 21.26)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [4][400/464]	Time  0.081 ( 0.104)	Data  0.000 ( 0.016)	Loss 5.4957e+00 (2.6928e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  75.00 ( 21.57)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [5][  0/464]	Time  6.468 ( 6.468)	Data  6.204 ( 6.204)	Loss 4.7675e+00 (4.7675e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 50.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [5][100/464]	Time  0.088 ( 0.153)	Data  0.000 ( 0.062)	Loss 1.5468e+01 (9.5489e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.31)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [5][200/464]	Time  0.100 ( 0.121)	Data  0.000 ( 0.031)	Loss 3.3730e+01 (3.5652e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 20.02)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [5][300/464]	Time  0.100 ( 0.110)	Data  0.000 ( 0.021)	Loss 2.6274e+01 (3.2529e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 20.43)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [5][400/464]	Time  0.087 ( 0.105)	Data  0.000 ( 0.016)	Loss 1.2378e+01 (2.8879e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 19.83)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [6][  0/464]	Time  6.654 ( 6.654)	Data  6.326 ( 6.326)	Loss 1.2563e+01 (1.2563e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [6][100/464]	Time  0.085 ( 0.151)	Data  0.005 ( 0.063)	Loss 4.2604e+00 (6.9573e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 20.30)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [6][200/464]	Time  0.099 ( 0.119)	Data  0.000 ( 0.032)	Loss 4.1601e+00 (5.5528e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.14)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [6][300/464]	Time  0.085 ( 0.108)	Data  0.000 ( 0.021)	Loss 5.8813e+00 (8.2315e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.77)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [6][400/464]	Time  0.087 ( 0.103)	Data  0.005 ( 0.016)	Loss 3.5040e+00 (9.8886e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 18.52)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [7][  0/464]	Time  6.627 ( 6.627)	Data  6.346 ( 6.346)	Loss 1.4259e+01 (1.4259e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [7][100/464]	Time  0.096 ( 0.150)	Data  0.000 ( 0.063)	Loss 8.7697e+00 (1.2643e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 12.62)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [7][200/464]	Time  0.085 ( 0.119)	Data  0.000 ( 0.032)	Loss 7.5929e+00 (1.5826e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 15.05)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [7][300/464]	Time  0.091 ( 0.109)	Data  0.000 ( 0.022)	Loss 6.9748e+00 (1.3878e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 14.95)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [7][400/464]	Time  0.096 ( 0.104)	Data  0.000 ( 0.016)	Loss 1.1034e+01 (1.3615e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 15.02)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [8][  0/464]	Time  6.551 ( 6.551)	Data  6.309 ( 6.309)	Loss 1.1270e+01 (1.1270e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 50.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [8][100/464]	Time  0.086 ( 0.153)	Data  0.005 ( 0.063)	Loss 6.6777e+00 (9.9471e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.05)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [8][200/464]	Time  0.086 ( 0.120)	Data  0.000 ( 0.032)	Loss 4.8412e+00 (9.3898e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 18.66)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [8][300/464]	Time  0.082 ( 0.109)	Data  0.000 ( 0.022)	Loss 4.1534e+00 (9.3979e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 18.69)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [8][400/464]	Time  0.077 ( 0.104)	Data  0.000 ( 0.016)	Loss 4.7199e+01 (9.8741e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 18.33)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [9][  0/464]	Time  6.723 ( 6.723)	Data  6.430 ( 6.430)	Loss 1.0717e+01 (1.0717e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [9][100/464]	Time  0.081 ( 0.153)	Data  0.000 ( 0.064)	Loss 1.2694e+02 (9.8421e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 16.58)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [9][200/464]	Time  0.117 ( 0.122)	Data  0.000 ( 0.033)	Loss 6.2265e+00 (8.5409e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 15.42)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [9][300/464]	Time  0.100 ( 0.114)	Data  0.000 ( 0.022)	Loss 1.4969e+01 (5.9129e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 16.78)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [9][400/464]	Time  0.081 ( 0.108)	Data  0.005 ( 0.017)	Loss 5.9353e+00 (4.6492e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 17.71)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [10][  0/464]	Time  6.751 ( 6.751)	Data  6.391 ( 6.391)	Loss 4.1119e+00 (4.1119e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [10][100/464]	Time  0.084 ( 0.152)	Data  0.000 ( 0.064)	Loss 4.3389e+00 (5.0392e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.06)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [10][200/464]	Time  0.081 ( 0.120)	Data  0.000 ( 0.032)	Loss 5.1786e+00 (4.6908e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 17.54)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [10][300/464]	Time  0.075 ( 0.110)	Data  0.001 ( 0.022)	Loss 3.6144e+00 (4.6389e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 18.69)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [10][400/464]	Time  0.090 ( 0.104)	Data  0.000 ( 0.016)	Loss 3.6306e+00 (4.3939e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.08)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [11][  0/464]	Time  6.828 ( 6.828)	Data  6.555 ( 6.555)	Loss 3.7727e+00 (3.7727e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [11][100/464]	Time  0.084 ( 0.157)	Data  0.000 ( 0.065)	Loss 3.3837e+00 (4.5608e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 19.55)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [11][200/464]	Time  0.083 ( 0.122)	Data  0.005 ( 0.033)	Loss 3.4699e+00 (7.6614e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 17.54)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [11][300/464]	Time  0.114 ( 0.111)	Data  0.000 ( 0.022)	Loss 2.2642e+02 (3.1837e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 16.28)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [11][400/464]	Time  0.091 ( 0.107)	Data  0.000 ( 0.017)	Loss 3.7214e+01 (4.4115e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 16.83)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [12][  0/464]	Time  6.745 ( 6.745)	Data  6.360 ( 6.360)	Loss 5.5867e+00 (5.5867e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [12][100/464]	Time  0.082 ( 0.152)	Data  0.000 ( 0.063)	Loss 7.0152e+00 (6.3628e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 21.53)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [12][200/464]	Time  0.082 ( 0.118)	Data  0.000 ( 0.032)	Loss 6.4963e+00 (6.8420e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 18.78)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [12][300/464]	Time  0.083 ( 0.107)	Data  0.000 ( 0.022)	Loss 5.8363e+00 (6.7783e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 19.10)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [12][400/464]	Time  0.083 ( 0.102)	Data  0.000 ( 0.016)	Loss 5.8389e+00 (6.8316e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.39)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [13][  0/464]	Time  6.789 ( 6.789)	Data  6.544 ( 6.544)	Loss 7.1216e+00 (7.1216e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 50.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [13][100/464]	Time  0.091 ( 0.155)	Data  0.000 ( 0.065)	Loss 7.3091e+00 (8.5945e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 20.05)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [13][200/464]	Time  0.085 ( 0.121)	Data  0.000 ( 0.033)	Loss 9.8072e+00 (8.2058e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.15)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [13][300/464]	Time  0.096 ( 0.111)	Data  0.001 ( 0.022)	Loss 5.6093e+00 (8.3563e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 19.93)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [13][400/464]	Time  0.086 ( 0.105)	Data  0.000 ( 0.017)	Loss 1.7925e+01 (9.4485e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 19.89)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [14][  0/464]	Time  7.305 ( 7.305)	Data  7.033 ( 7.033)	Loss 9.5905e+00 (9.5905e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [14][100/464]	Time  0.096 ( 0.159)	Data  0.005 ( 0.070)	Loss 9.2576e+01 (2.3605e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 18.81)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [14][200/464]	Time  0.092 ( 0.123)	Data  0.000 ( 0.036)	Loss 1.0607e+01 (2.1631e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 21.52)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [14][300/464]	Time  0.081 ( 0.112)	Data  0.000 ( 0.024)	Loss 1.0725e+01 (1.8719e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.68)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [14][400/464]	Time  0.099 ( 0.106)	Data  0.000 ( 0.018)	Loss 8.4448e+00 (1.6339e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.07)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [15][  0/464]	Time  6.824 ( 6.824)	Data  6.447 ( 6.447)	Loss 7.5753e+00 (7.5753e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [15][100/464]	Time  0.084 ( 0.159)	Data  0.000 ( 0.064)	Loss 4.4870e+00 (5.3725e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.78)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [15][200/464]	Time  0.119 ( 0.124)	Data  0.000 ( 0.033)	Loss 1.3283e+01 (5.8748e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 19.40)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [15][300/464]	Time  0.087 ( 0.112)	Data  0.000 ( 0.022)	Loss 1.1283e+01 (6.6496e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 20.02)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [15][400/464]	Time  0.081 ( 0.106)	Data  0.000 ( 0.017)	Loss 9.7984e+00 (1.1213e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 20.01)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [16][  0/464]	Time  6.517 ( 6.517)	Data  6.203 ( 6.203)	Loss 8.5358e+00 (8.5358e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [16][100/464]	Time  0.088 ( 0.151)	Data  0.000 ( 0.062)	Loss 6.0349e+00 (1.0984e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.30)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [16][200/464]	Time  0.082 ( 0.119)	Data  0.000 ( 0.032)	Loss 2.5015e+01 (1.1795e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.02)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [16][300/464]	Time  0.082 ( 0.108)	Data  0.004 ( 0.021)	Loss 4.1084e+01 (2.0128e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.27)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [16][400/464]	Time  0.084 ( 0.103)	Data  0.000 ( 0.016)	Loss 9.8300e+01 (3.0272e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 20.51)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [17][  0/464]	Time  6.617 ( 6.617)	Data  6.377 ( 6.377)	Loss 7.7576e+01 (7.7576e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [17][100/464]	Time  0.092 ( 0.153)	Data  0.000 ( 0.064)	Loss 3.1218e+01 (1.1588e+02)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.30)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [17][200/464]	Time  0.084 ( 0.120)	Data  0.000 ( 0.032)	Loss 7.1205e+00 (6.5895e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.77)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [17][300/464]	Time  0.086 ( 0.109)	Data  0.000 ( 0.022)	Loss 1.2316e+01 (5.0658e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.85)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [17][400/464]	Time  0.094 ( 0.104)	Data  0.000 ( 0.017)	Loss 6.4466e+00 (4.0783e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.76)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [18][  0/464]	Time  6.653 ( 6.653)	Data  6.423 ( 6.423)	Loss 5.8202e+00 (5.8202e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [18][100/464]	Time  0.082 ( 0.151)	Data  0.000 ( 0.064)	Loss 7.3542e+00 (7.2605e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 15.59)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [18][200/464]	Time  0.084 ( 0.119)	Data  0.000 ( 0.032)	Loss 8.0065e+01 (1.3413e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 16.79)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [18][300/464]	Time  0.083 ( 0.108)	Data  0.000 ( 0.022)	Loss 1.6738e+02 (4.2771e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 17.94)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [18][400/464]	Time  0.090 ( 0.103)	Data  0.000 ( 0.016)	Loss 2.8642e+01 (5.2802e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 18.33)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [19][  0/464]	Time  6.817 ( 6.817)	Data  6.458 ( 6.458)	Loss 1.8257e+01 (1.8257e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [19][100/464]	Time  0.085 ( 0.155)	Data  0.000 ( 0.064)	Loss 8.5808e+00 (1.0037e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 18.07)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [19][200/464]	Time  0.082 ( 0.122)	Data  0.000 ( 0.033)	Loss 4.2733e+01 (9.6381e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 18.66)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [19][300/464]	Time  0.082 ( 0.110)	Data  0.000 ( 0.022)	Loss 1.3091e+02 (2.6783e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.77)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [19][400/464]	Time  0.093 ( 0.104)	Data  0.000 ( 0.017)	Loss 2.4076e+01 (3.2043e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 20.14)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [20][  0/464]	Time  6.582 ( 6.582)	Data  6.283 ( 6.283)	Loss 1.9959e+01 (1.9959e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [20][100/464]	Time  0.086 ( 0.152)	Data  0.000 ( 0.063)	Loss 6.5217e+00 (1.8527e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 21.78)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [20][200/464]	Time  0.084 ( 0.119)	Data  0.000 ( 0.032)	Loss 5.3577e+00 (1.2135e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 20.27)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [20][300/464]	Time  0.081 ( 0.108)	Data  0.000 ( 0.021)	Loss 1.6151e+01 (1.0275e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 19.85)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [20][400/464]	Time  0.082 ( 0.103)	Data  0.000 ( 0.016)	Loss 2.6061e+01 (1.2638e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.58)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [21][  0/464]	Time  6.604 ( 6.604)	Data  6.350 ( 6.350)	Loss 5.6345e+00 (5.6345e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [21][100/464]	Time  0.085 ( 0.151)	Data  0.000 ( 0.063)	Loss 4.3495e+01 (2.8190e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 20.54)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [21][200/464]	Time  0.094 ( 0.120)	Data  0.000 ( 0.032)	Loss 3.0477e+01 (3.3963e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 19.78)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [21][300/464]	Time  0.085 ( 0.108)	Data  0.000 ( 0.022)	Loss 4.6961e+01 (5.6954e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 19.35)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [21][400/464]	Time  0.083 ( 0.103)	Data  0.000 ( 0.016)	Loss 1.5879e+01 (4.9200e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 18.52)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [22][  0/464]	Time  6.500 ( 6.500)	Data  6.242 ( 6.242)	Loss 7.3843e+00 (7.3843e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [22][100/464]	Time  0.084 ( 0.149)	Data  0.000 ( 0.062)	Loss 5.1293e+00 (8.9593e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 17.82)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [22][200/464]	Time  0.084 ( 0.118)	Data  0.000 ( 0.031)	Loss 1.5288e+01 (8.4137e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 17.41)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [22][300/464]	Time  0.091 ( 0.108)	Data  0.000 ( 0.021)	Loss 1.3636e+01 (8.4784e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 17.86)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [22][400/464]	Time  0.090 ( 0.102)	Data  0.000 ( 0.016)	Loss 1.7219e+01 (8.4645e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 18.20)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [23][  0/464]	Time  6.356 ( 6.356)	Data  5.962 ( 5.962)	Loss 5.7075e+00 (5.7075e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [23][100/464]	Time  0.086 ( 0.149)	Data  0.000 ( 0.059)	Loss 4.8074e+00 (1.6969e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 17.57)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [23][200/464]	Time  0.084 ( 0.118)	Data  0.000 ( 0.030)	Loss 1.2507e+01 (1.4446e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.14)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [23][300/464]	Time  0.086 ( 0.109)	Data  0.000 ( 0.020)	Loss 1.9944e+01 (3.2186e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 21.68)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [23][400/464]	Time  0.082 ( 0.104)	Data  0.000 ( 0.016)	Loss 1.1945e+01 (2.8646e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 22.26)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [24][  0/464]	Time  7.133 ( 7.133)	Data  6.822 ( 6.822)	Loss 7.7175e+00 (7.7175e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 50.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [24][100/464]	Time  0.082 ( 0.157)	Data  0.000 ( 0.068)	Loss 4.8520e+00 (7.2021e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 25.50)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [24][200/464]	Time  0.085 ( 0.121)	Data  0.000 ( 0.035)	Loss 6.4373e+00 (6.3699e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [24][300/464]	Time  0.075 ( 0.109)	Data  0.000 ( 0.023)	Loss 4.2157e+00 (6.0684e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  75.00 ( 23.09)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [24][400/464]	Time  0.082 ( 0.103)	Data  0.000 ( 0.018)	Loss 6.0555e+00 (5.9233e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 22.57)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [25][  0/464]	Time  6.733 ( 6.733)	Data  6.338 ( 6.338)	Loss 1.0499e+01 (1.0499e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [25][100/464]	Time  0.086 ( 0.152)	Data  0.000 ( 0.063)	Loss 1.0944e+01 (7.0275e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 21.78)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [25][200/464]	Time  0.093 ( 0.121)	Data  0.000 ( 0.032)	Loss 1.6299e+01 (9.3499e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.52)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [25][300/464]	Time  0.078 ( 0.110)	Data  0.000 ( 0.022)	Loss 4.7351e+00 (7.9927e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 20.60)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [25][400/464]	Time  0.085 ( 0.104)	Data  0.000 ( 0.016)	Loss 4.3181e+00 (7.4718e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 20.20)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [26][  0/464]	Time  7.725 ( 7.725)	Data  7.347 ( 7.347)	Loss 3.5194e+00 (3.5194e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [26][100/464]	Time  0.111 ( 0.162)	Data  0.000 ( 0.073)	Loss 8.6574e+00 (5.0253e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 21.78)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [26][200/464]	Time  0.084 ( 0.124)	Data  0.000 ( 0.037)	Loss 5.2701e+01 (3.1936e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 20.65)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [26][300/464]	Time  0.087 ( 0.112)	Data  0.000 ( 0.025)	Loss 1.2862e+01 (3.4086e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  75.00 ( 18.94)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [26][400/464]	Time  0.082 ( 0.106)	Data  0.000 ( 0.019)	Loss 1.0933e+01 (2.8760e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 19.70)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [27][  0/464]	Time  6.802 ( 6.802)	Data  6.491 ( 6.491)	Loss 1.2709e+01 (1.2709e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [27][100/464]	Time  0.079 ( 0.155)	Data  0.000 ( 0.065)	Loss 8.3312e+00 (1.0152e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 20.54)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [27][200/464]	Time  0.085 ( 0.122)	Data  0.000 ( 0.033)	Loss 5.4279e+00 (8.2385e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.77)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [27][300/464]	Time  0.083 ( 0.111)	Data  0.000 ( 0.022)	Loss 3.9136e+00 (7.2760e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 21.01)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [27][400/464]	Time  0.084 ( 0.105)	Data  0.000 ( 0.017)	Loss 4.4935e+00 (6.5766e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.45)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [28][  0/464]	Time  6.586 ( 6.586)	Data  6.273 ( 6.273)	Loss 4.3059e+00 (4.3059e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  75.00 ( 75.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [28][100/464]	Time  0.076 ( 0.150)	Data  0.000 ( 0.062)	Loss 3.9387e+00 (4.0740e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.53)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [28][200/464]	Time  0.091 ( 0.118)	Data  0.000 ( 0.032)	Loss 3.3970e+00 (3.8462e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 21.64)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [28][300/464]	Time  0.089 ( 0.108)	Data  0.000 ( 0.021)	Loss 3.4104e+00 (3.7441e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 23.09)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [28][400/464]	Time  0.090 ( 0.103)	Data  0.000 ( 0.016)	Loss 3.5646e+00 (3.6662e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 24.06)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [29][  0/464]	Time  6.320 ( 6.320)	Data  5.992 ( 5.992)	Loss 3.3501e+00 (3.3501e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [29][100/464]	Time  0.076 ( 0.148)	Data  0.000 ( 0.060)	Loss 3.2644e+00 (3.3956e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 26.24)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [29][200/464]	Time  0.101 ( 0.117)	Data  0.000 ( 0.030)	Loss 3.8140e+00 (3.3718e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 27.99)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [29][300/464]	Time  0.094 ( 0.107)	Data  0.000 ( 0.020)	Loss 3.1293e+00 (3.3676e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 26.50)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [29][400/464]	Time  0.087 ( 0.101)	Data  0.000 ( 0.015)	Loss 3.1682e+00 (3.3506e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 26.18)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [30][  0/464]	Time  6.589 ( 6.589)	Data  6.208 ( 6.208)	Loss 3.2261e+00 (3.2261e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [30][100/464]	Time  0.084 ( 0.149)	Data  0.000 ( 0.062)	Loss 3.1102e+00 (3.3139e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 27.48)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [30][200/464]	Time  0.086 ( 0.117)	Data  0.000 ( 0.032)	Loss 3.0492e+00 (3.2956e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 26.12)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [30][300/464]	Time  0.084 ( 0.107)	Data  0.000 ( 0.021)	Loss 3.6643e+00 (3.3198e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 26.41)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [30][400/464]	Time  0.089 ( 0.102)	Data  0.000 ( 0.016)	Loss 3.5699e+00 (3.3534e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 25.44)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [31][  0/464]	Time  6.511 ( 6.511)	Data  6.261 ( 6.261)	Loss 3.6399e+00 (3.6399e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 50.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [31][100/464]	Time  0.082 ( 0.147)	Data  0.005 ( 0.062)	Loss 3.3110e+00 (3.2689e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 23.02)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [31][200/464]	Time  0.081 ( 0.116)	Data  0.000 ( 0.032)	Loss 3.0576e+00 (3.3347e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 25.62)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [31][300/464]	Time  0.093 ( 0.106)	Data  0.001 ( 0.021)	Loss 5.1965e+01 (5.8693e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 27.16)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [31][400/464]	Time  0.085 ( 0.101)	Data  0.000 ( 0.016)	Loss 2.0704e+02 (1.6218e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  75.00 ( 27.12)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [32][  0/464]	Time  6.303 ( 6.303)	Data  5.992 ( 5.992)	Loss 8.3604e+01 (8.3604e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 25.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [32][100/464]	Time  0.081 ( 0.146)	Data  0.000 ( 0.060)	Loss 5.3438e+00 (1.8271e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 24.26)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [32][200/464]	Time  0.084 ( 0.117)	Data  0.000 ( 0.031)	Loss 4.2216e+00 (1.2021e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 24.13)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [32][300/464]	Time  0.094 ( 0.107)	Data  0.000 ( 0.021)	Loss 7.3495e+00 (9.7126e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 23.75)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [32][400/464]	Time  0.088 ( 0.102)	Data  0.005 ( 0.016)	Loss 9.2561e+00 (8.6980e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 22.76)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [33][  0/464]	Time  6.634 ( 6.634)	Data  6.290 ( 6.290)	Loss 6.2048e+00 (6.2048e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 (  0.00)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [33][100/464]	Time  0.081 ( 0.151)	Data  0.000 ( 0.063)	Loss 8.7347e+00 (7.8527e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  50.00 ( 21.53)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [33][200/464]	Time  0.082 ( 0.119)	Data  0.000 ( 0.032)	Loss 8.1374e+00 (1.0693e+01)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst  25.00 ( 19.78)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [33][300/464]	Time  0.082 ( 0.108)	Data  0.000 ( 0.022)	Loss 4.4050e+00 (9.3685e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 18.27)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
Epoch: [33][400/464]	Time  0.081 ( 0.102)	Data  0.001 ( 0.016)	Loss 3.7772e+00 (8.2035e+00)	Global Loss 0.0000e+00 (0.0000e+00)	Dense Loss 0.0000e+00 (0.0000e+00)	Global Proto Loss 0.0000e+00 (0.0000e+00)	Dense Proto Loss 0.0000e+00 (0.0000e+00)	Acc@Inst   0.00 ( 17.58)	Acc@Global Proto   0.00 (  0.00)	Acc@Dense Proto   0.00 (  0.00)
