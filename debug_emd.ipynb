{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from random import sample\n",
    "import sys\n",
    "sys.path.append(\"/home/siyi/project/PCL/pcl\")\n",
    "from head import Yolov8Head, MlpHead\n",
    "from backbone import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1024  # 这是 q_dense 的通道维度\n",
    "height, width = 7, 7  # 这是 q_dense 的空间维度\n",
    "r = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue2 = torch.randn(channels, r, height, width)\n",
    "queue2 = nn.functional.normalize(queue2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 4, 7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue2.detach().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue2_ptr = torch.zeros(1, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_global_neg = torch.einsum('nc,ck->nk', [q_global, queue.clone().detach()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过emd计算相似度\n",
    "x1 = torch.randn(1, 1024, 7, 7)\n",
    "x2 = torch.randn(1, 1024, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_knopp(a, b, cost_matrix, epsilon, max_iter=100):\n",
    "    \"\"\"\n",
    "    Compute Sinkhorn distance (approximation of EMD) between distributions a and b\n",
    "    with regularization parameter epsilon.\n",
    "    \"\"\"\n",
    "    n, m = cost_matrix.shape\n",
    "    u = torch.ones(n, dtype=torch.float32, device=a.device) / n\n",
    "    v = torch.ones(m, dtype=torch.float32, device=b.device) / m\n",
    "\n",
    "    K = torch.exp(-cost_matrix / epsilon)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        u = a / (K @ v)\n",
    "        v = b / (K.t() @ u)\n",
    "\n",
    "    transport_plan = torch.diag(u) @ K @ torch.diag(v)\n",
    "    distance = torch.sum(transport_plan * cost_matrix)\n",
    "\n",
    "    return distance, transport_plan\n",
    "\n",
    "\n",
    "def compute_emd_torch(x, y, epsilon=1e-3, max_iter=100):\n",
    "    \"\"\"\n",
    "    Compute the EMD between two distributions using Sinkhorn-Knopp algorithm.\n",
    "    x, y should be histograms or distributions.\n",
    "    \"\"\"\n",
    "    assert x.shape == y.shape, \"Input distributions must have the same shape.\"\n",
    "    n = x.shape[0]\n",
    "\n",
    "    cost_matrix = torch.cdist(x.unsqueeze(0), y.unsqueeze(0), p=2).squeeze(0)\n",
    "    print(\"cost_matrix.shape:\", cost_matrix.shape)\n",
    "    a = torch.ones(n, dtype=torch.float32, device=x.device) / n\n",
    "    b = torch.ones(n, dtype=torch.float32, device=y.device) / n\n",
    "\n",
    "    emd, transport_plan = sinkhorn_knopp(a, b, cost_matrix, epsilon, max_iter)\n",
    "\n",
    "    return emd.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_matrix.shape: torch.Size([1024, 7, 7])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcompute_emd_torch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 35\u001B[0m, in \u001B[0;36mcompute_emd_torch\u001B[0;34m(x, y, epsilon, max_iter)\u001B[0m\n\u001B[1;32m     32\u001B[0m a \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(n, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32, device\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;241m/\u001B[39m n\n\u001B[1;32m     33\u001B[0m b \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(n, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32, device\u001B[38;5;241m=\u001B[39my\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;241m/\u001B[39m n\n\u001B[0;32m---> 35\u001B[0m emd, transport_plan \u001B[38;5;241m=\u001B[39m \u001B[43msinkhorn_knopp\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcost_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m emd\u001B[38;5;241m.\u001B[39mitem()\n",
      "Cell \u001B[0;32mIn[11], line 6\u001B[0m, in \u001B[0;36msinkhorn_knopp\u001B[0;34m(a, b, cost_matrix, epsilon, max_iter)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msinkhorn_knopp\u001B[39m(a, b, cost_matrix, epsilon, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m):\n\u001B[1;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    Compute Sinkhorn distance (approximation of EMD) between distributions a and b\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m    with regularization parameter epsilon.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m     n, m \u001B[38;5;241m=\u001B[39m cost_matrix\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m      7\u001B[0m     u \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(n, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32, device\u001B[38;5;241m=\u001B[39ma\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;241m/\u001B[39m n\n\u001B[1;32m      8\u001B[0m     v \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32, device\u001B[38;5;241m=\u001B[39mb\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;241m/\u001B[39m m\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "compute_emd_torch(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinkhornDistance(torch.nn.Module):\n",
    "    def __init__(self, eps, max_iter, reduction=\"mean\"):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # 扁平化空间维度\n",
    "        batch_size, num_points, height, width = x.size()\n",
    "        x = x.view(batch_size, num_points, -1)\n",
    "        y = y.view(batch_size, num_points, -1)\n",
    "\n",
    "        # 归一化特征向量\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "        y = F.normalize(y, p=2, dim=-1)\n",
    "\n",
    "        # 计算余弦相似度矩阵并归一化\n",
    "        cost_matrix = 1 - F.cosine_similarity(x.unsqueeze(2), y.unsqueeze(1), dim=-1)\n",
    "        cost_matrix = cost_matrix / cost_matrix.max()  # 归一化到 [0, 1] 范围内\n",
    "\n",
    "        # 初始分布\n",
    "        u = torch.ones(batch_size, num_points).to(x.device) / num_points\n",
    "        v = torch.ones(batch_size, num_points).to(x.device) / num_points\n",
    "\n",
    "        # Sinkhorn 迭代\n",
    "        for _ in range(self.max_iter):\n",
    "            u = 1.0 / (cost_matrix.bmm(v.unsqueeze(-1)).squeeze(-1) + self.eps)\n",
    "            v = 1.0 / (\n",
    "                cost_matrix.transpose(1, 2).bmm(u.unsqueeze(-1)).squeeze(-1) + self.eps\n",
    "            )\n",
    "\n",
    "        # 计算Wasserstein距离\n",
    "        distance = (u.unsqueeze(-1) * cost_matrix * v.unsqueeze(-2)).sum(dim=(1, 2))\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            distance = distance.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            distance = distance.sum()\n",
    "\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = SinkhornDistance(eps=0.5, max_iter=100, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1004.6594)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.rand(1, 1024, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1004.5660)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(x1, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0227)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SinkhornDistance(torch.nn.Module):\n",
    "    def __init__(self, eps=1e-3, max_iter=100, reduction='mean'):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # 扁平化空间维度\n",
    "        batch_size, num_points, height, width = x.size()\n",
    "        x = x.view(batch_size, num_points, -1)\n",
    "        y = y.view(batch_size, num_points, -1)\n",
    "\n",
    "        # 归一化特征向量到概率分布\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        y = F.softmax(y, dim=-1)\n",
    "\n",
    "        # 计算 Euclidean 距离作为成本矩阵\n",
    "        cost_matrix = torch.cdist(x, y, p=2)\n",
    "\n",
    "        # 初始分布\n",
    "        u = torch.ones(batch_size, num_points).to(x.device) / num_points\n",
    "        v = torch.ones(batch_size, num_points).to(x.device) / num_points\n",
    "\n",
    "        # Sinkhorn 迭代\n",
    "        for _ in range(self.max_iter):\n",
    "            u = self.eps / (cost_matrix.bmm(v.unsqueeze(-1)).squeeze(-1) + self.eps)\n",
    "            v = self.eps / (cost_matrix.transpose(1, 2).bmm(u.unsqueeze(-1)).squeeze(-1) + self.eps)\n",
    "\n",
    "        # 计算 Wasserstein 距离\n",
    "        distance = (u.unsqueeze(-1) * cost_matrix * v.unsqueeze(-2)).sum(dim=(1, 2))\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            distance = distance.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            distance = distance.sum()\n",
    "\n",
    "        return distance\n",
    "\n",
    "# 示例使用\n",
    "x1 = torch.randn(1, 1024, 7, 7)\n",
    "x2 = torch.randn(1, 1024, 7, 7)\n",
    "sinkhorn = SinkhornDistance()\n",
    "distance = sinkhorn(x1, x2)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "q_dense = torch.rand(20, 1024, 7, 7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "q_dense_1 = q_dense[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1024, 7, 7])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dense_1.unsqueeze(0).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
