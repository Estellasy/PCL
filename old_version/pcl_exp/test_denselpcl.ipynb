{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import builtins\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet50'\n"
     ]
    }
   ],
   "source": [
    "print(\"=> creating model '{}'\".format(\"resnet50\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from random import sample\n",
    "\n",
    "# 这里r需要修改 每次选择的原型数量和队列大小相同 应该为<原型数量 刚开始时没有那么多原型 queue_size要选择的原型数量多\n",
    "class DenseCL(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a DenseCL model, change the MLP layer into dense layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 base_encoder,  # 也就是backbone\n",
    "                 head=None, # head\n",
    "                 dim=128, \n",
    "                 r=16384, \n",
    "                 m=0.999, \n",
    "                 T=0.1, \n",
    "                 loss_lambda=0.5,   # 损失权重\n",
    "                 mlp=False):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 128)\n",
    "        r: queue size; number of negative samples/prototypes (default: 16384)\n",
    "        m: momentum for updating key encoder (default: 0.999)\n",
    "        T: softmax temperature \n",
    "        mlp: whether to use mlp projection\n",
    "        \"\"\"\n",
    "        super(DenseCL, self).__init__()\n",
    "        \n",
    "        self.r = r\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        \n",
    "        # 创建编码器\n",
    "        # 其中num_classes=dim是fc层的输出维度\n",
    "        self.encoder_q = nn.Sequential(\n",
    "            base_encoder(base_encoder(num_classes=dim)),\n",
    "            nn.Sequential()\n",
    "        )\n",
    "        \n",
    "        self.encoder_k = nn.Sequential(\n",
    "            base_encoder(base_encoder(num_classes=dim)),\n",
    "            nn.Sequential()\n",
    "        )\n",
    "        \n",
    "        # 硬编码mlp层\n",
    "        if mlp:\n",
    "            dim_mlp = self.encoder_q[0].fc.weight.shape[1]\n",
    "            # 删除原avgpool/fc层，并替换mlp\n",
    "            self.encoder_q[0].avgpool = nn.Identity()\n",
    "            self.encoder_q[0].fc = nn.Identity()\n",
    "            self.encoder_k[0].avgpool = nn.Identity()\n",
    "            self.encoder_k[0].fc = nn.Identity()\n",
    "            \n",
    "            # 更新neck\n",
    "            self.encoder_q[1] = DenseNeck(dim_mlp, dim_mlp, dim)\n",
    "            self.encoder_k[1] = DenseNeck(dim_mlp, dim_mlp, dim)\n",
    "                \n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # 初始化encoder_k的参数为encoder_q的参数\n",
    "            param_k.requires_grad = False  # encoder_k不进行梯度更新\n",
    "            \n",
    "        # 创建两个队列 分别为global和dense\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, r))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "        \n",
    "        self.register_buffer(\"queue2\",  torch.randn(dim, r))\n",
    "        self.queue2 = nn.functional.normalize(self.queue2, dim=0)\n",
    "        self.register_buffer(\"queue2_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        # gather keys before updating queue\n",
    "        keys = concat_all_gather(keys)\n",
    "\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.queue_len % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.transpose(0, 1)\n",
    "        ptr = (ptr + batch_size) % self.queue_len  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue2(self, keys):\n",
    "        # gather keys before updating queue\n",
    "        keys = concat_all_gather(keys)\n",
    "\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue2_ptr)\n",
    "        assert self.queue_len % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue2[:, ptr:ptr + batch_size] = keys.transpose(0, 1)\n",
    "        ptr = (ptr + batch_size) % self.queue_len  # move pointer\n",
    "\n",
    "        self.queue2_ptr[0] = ptr\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_ddp(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(batch_size_all).cuda()\n",
    "\n",
    "        # broadcast to all gpus\n",
    "        torch.distributed.broadcast(idx_shuffle, src=0)\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        # shuffled index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this], idx_unshuffle\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_ddp(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # restored index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this]\n",
    "    \n",
    "    def forward(self, im_q, im_k=None, is_eval=False, cluster_global=None, cluster_dense=None, index=None):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "            is_eval: return momentum embeddings (used for clustering)\n",
    "            cluster_result: cluster assignments, centroids, and density\n",
    "            index: indices for training samples\n",
    "        Output:\n",
    "            logits, targets, proto_logits, proto_targets\n",
    "        \"\"\"\n",
    "        if is_eval:\n",
    "            # 获取encoder_k输出\n",
    "            k_b = self.encoderk_features(im_q)\n",
    "            # mlp层输出\n",
    "            k, k_grid, _ = self.encoder_k[1](k_b)  # keys: NxC; NxCxS^2\n",
    "            k = nn.functional.normalize(k, dim=1)   # global\n",
    "            k_grid = nn.functional.normalize(k_grid, dim=1)  # dense\n",
    "            return k, k_grid\n",
    "\n",
    "        # 转为内存中的连续存储格式，提高访问效率\n",
    "        im_q = im_q.contiguous()\n",
    "        im_k = im_k.contiguous()\n",
    "        # compute query features\n",
    "        q_b = self.encoderq_features(im_q)  # backbone features\n",
    "        q, q_grid, q2 = self.encoder_q[1](q_b)  # queries: NxC; NxCxS^2\n",
    "        q_b = q_b.view(q_b.size(0), q_b.size(1), -1)\n",
    "        \n",
    "        q = nn.functional.normalize(q, dim=1)   # global\n",
    "        q2 = nn.functional.normalize(q2, dim=1) # dense\n",
    "        q_grid = nn.functional.normalize(q_grid, dim=1)\n",
    "        q_b = nn.functional.normalize(q_b, dim=1)\n",
    "        \n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()  # update the key encoder\n",
    "            \n",
    "            # shuffle for making use of BN\n",
    "            im_k, idx_unshuffle = self._batch_shuffle_ddp(im_k)\n",
    "            \n",
    "            # 获取encoder_k输出\n",
    "            k_b = self.encoderk_features(im_k)  # encoder_k features\n",
    "            # mlp层输出\n",
    "            k, k_grid, k2 = self.encoder_k[1](k_b)  # keys: NxC; NxCxS^2\n",
    "            k_b = k_b.view(k_b.size(0), k_b.size(1), -1)\n",
    "            \n",
    "            k = nn.functional.normalize(k, dim=1)   # global\n",
    "            k2 = nn.functional.normalize(k2, dim=1)  # dense\n",
    "            k_grid = nn.functional.normalize(k_grid, dim=1)\n",
    "            k_b = nn.functional.normalize(k_b, dim=1)\n",
    "            \n",
    "            # undo shuffle\n",
    "            k = self._batch_unshuffle_ddp(k, idx_unshuffle)\n",
    "            k2 = self._batch_unshuffle_ddp(k2, idx_unshuffle)\n",
    "            k_grid = self._batch_unshuffle_ddp(k_grid, idx_unshuffle)\n",
    "            k_b = self._batch_unshuffle_ddp(k_b, idx_unshuffle)\n",
    "            \n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        # 计算正样本对数似然 点积\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)  # 正样本\n",
    "        # negative logits: NxK 矩阵乘法\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()]) # 负样本\n",
    "\n",
    "        # feat point to set sim\n",
    "        # 计算 q_b 和 k_b 之间的相似度矩阵\n",
    "        backbone_sim_matrix = torch.matmul(q_b.permute(0, 2, 1), k_b)\n",
    "        # 得到最大的索引\n",
    "        densecl_sim_q = backbone_sim_matrix.max(dim=2)[1]   # NxS^2\n",
    "        \n",
    "        l_pos_dense = densecl_sim_q.view(-1).unsqueeze(-1)  # NS^2x1\n",
    "        \n",
    "        q_grid = q_grid.permute(0, 2, 1)\n",
    "        q_grid = q_grid.reshape(-1, q_grid.size(2))\n",
    "        l_neg_dense = torch.einsum('nc,ck->nk', [q_grid,\n",
    "                                            self.queue2.clone().detach()])\n",
    "        \n",
    "        # 损失计算\n",
    "        logits_global = torch.cat([l_pos, l_neg], dim=1)  # Nx(1+K)\n",
    "        logits_dense = torch.cat([l_pos_dense, l_neg_dense], dim=1)\n",
    "        # apply temperature\n",
    "        logits_global /= self.T\n",
    "        logits_dense /= self.T\n",
    "        # labels: postive key indicators\n",
    "        # 每个样本的标签为 0 表示正样本\n",
    "        labels_global = torch.zeros(logits_global.shape[0], dtype=torch.long).cuda()\n",
    "        labels_dense = torch.zeros(logits_dense.shape[0], dtype=torch.long).cuda()\n",
    "        \n",
    "        self._dequeue_and_enqueue(k)\n",
    "        self._dequeue_and_enqueue2(k2)\n",
    "    \n",
    "        result = dict()\n",
    "        \n",
    "        # prototypical contrast\n",
    "        if cluster_global is not None:\n",
    "            proto_labels_global = []\n",
    "            proto_logits_global = []\n",
    "            for n, (im2cluster, prototypes, density) in enumerate(zip(cluster_global['im2cluster'], cluster_global['centroids'], cluster_global['density'])):\n",
    "                # get positive prototypes\n",
    "                pos_proto_id_global = im2cluster[index]\n",
    "                pos_prototypes_global = prototypes[pos_proto_id_global]\n",
    "                \n",
    "                # 采样负样本\n",
    "                all_proto_id_global = [i for i in range(im2cluster.max()+1)]\n",
    "                neg_proto_id_global = set(all_proto_id_global) - set(pos_proto_id_global.tolist())\n",
    "                \n",
    "                # 随机采样r个原型\n",
    "                neg_proto_id_global = sample(neg_proto_id_global, self.r)\n",
    "                neg_prototypes_global = prototypes[neg_proto_id_global]\n",
    "                \n",
    "                proto_selected_global = torch.cat([pos_prototypes_global, neg_prototypes_global], dim=0)\n",
    "                \n",
    "                # compute prototypical logits\n",
    "                logits_proto_global = torch.mm(q, proto_selected_global.t())\n",
    "                \n",
    "                # targets for prototype assignment\n",
    "                labels_proto_global = torch.linspace(0, q.size(0)-1, steps=q.size(0)).long().cuda()\n",
    "                \n",
    "                # scaling temperatures for the selected prototypes\n",
    "                temp_proto_global = density[torch.cat([pos_proto_id_global,torch.LongTensor(neg_proto_id_global).cuda()],dim=0)]  \n",
    "                logits_proto_global /= temp_proto_global\n",
    "                \n",
    "                proto_labels_global.append(labels_proto_global)\n",
    "                proto_logits_global.append(logits_proto_global)\n",
    "                \n",
    "            result['global'] = [logits_global, labels_global, proto_logits_global, proto_labels_global]\n",
    "        else:\n",
    "            result['global'] = [logits_global, labels_global, None, None]\n",
    "\n",
    "        if cluster_dense is not None:\n",
    "            # TODO 这里采样r个原型修改逻辑 采样r个原型 这里r比较小\n",
    "            # batch的淘汰机制需要确认\n",
    "            proto_labels_dense = []\n",
    "            proto_logits_dense = []\n",
    "            for n, (im2cluster, prototypes, density) in enumerate(zip(cluster_dense['im2cluster'], cluster_dense['centroids'], cluster_dense['density'])):\n",
    "                # get positive prototypes\n",
    "                pos_proto_id_dense = im2cluster[index]\n",
    "                pos_prototypes_dense = prototypes[pos_proto_id_dense]\n",
    "                \n",
    "                # 采样负样本\n",
    "                all_proto_id_dense = [i for i in range(im2cluster.max()+1)]\n",
    "                neg_proto_id_dense = set(all_proto_id_dense) - set(pos_proto_id_dense.tolist())\n",
    "                \n",
    "                # 随机采样r个原型\n",
    "                neg_proto_id_dense = sample(neg_proto_id_dense, self.r)\n",
    "                neg_prototypes_dense = prototypes[neg_proto_id_dense]\n",
    "                \n",
    "                proto_selected_dense = torch.cat([pos_prototypes_dense, neg_prototypes_dense], dim=0)\n",
    "                \n",
    "                # compute prototypical logits\n",
    "                logits_proto_dense = torch.mm(q, proto_selected_dense.t())\n",
    "                \n",
    "                # targets for prototype assignment\n",
    "                labels_proto_dense = torch.linspace(0, q.size(0)-1, steps=q.size(0)).long().cuda()\n",
    "                \n",
    "                # scaling temperatures for the selected prototypes\n",
    "                temp_proto_dense = density[torch.cat([pos_proto_id_dense,torch.LongTensor(neg_proto_id_dense).cuda()],dim=0)]\n",
    "                logits_proto_dense /= temp_proto_dense\n",
    "                \n",
    "                proto_labels_dense.append(labels_proto_dense)\n",
    "                proto_logits_dense.append(logits_proto_dense)\n",
    "            \n",
    "            result['dense'] = [logits_dense, labels_dense, proto_logits_dense, proto_labels_dense]\n",
    "        else:\n",
    "            result['dense'] = [logits_dense, labels_dense, None, None]\n",
    "\n",
    "        return result\n",
    "\n",
    "            \n",
    "    def encoderq_features(self, im_q):\n",
    "        features = im_q\n",
    "        # 提取avgpool层之前的特征\n",
    "        for name, layer in self.encoder_q[0].named_children():\n",
    "            if name == 'avgpool':\n",
    "                break\n",
    "            features = layer(features)\n",
    "        return features\n",
    "        \n",
    "    def encoderk_features(self, im_k):\n",
    "        features = im_k\n",
    "        # 提取avgpool层之前的特征\n",
    "        for name, layer in self.encoder_k[0].named_children():\n",
    "            if name == 'avgpool':\n",
    "                break\n",
    "            features = layer(features)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "# utils\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors.\n",
    "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "    \"\"\"\n",
    "    tensors_gather = [torch.ones_like(tensor)\n",
    "        for _ in range(torch.distributed.get_world_size())]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output\n",
    "\n",
    "\n",
    "class DenseNeck(nn.Module):\n",
    "    def __init__(self, in_channels, hid_channels, out_channels):\n",
    "        super(DenseNeck, self).__init__()\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # mlp1 fc-relu-fc\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, hid_channels), nn.ReLU(inplace=True),\n",
    "            nn.Linear(hid_channels, out_channels))\n",
    "        # mlp2 conv1x1-relu-conv1x1\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hid_channels, 1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hid_channels, out_channels, 1)\n",
    "        )\n",
    "        self.avgpool2 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # avgpool\n",
    "        avgpooled_x = self.avgpool(x)\n",
    "        # mlp1\n",
    "        avgpooled_x = self.mlp(avgpooled_x.view(avgpooled_x.size(0), -1))\n",
    "        \n",
    "        # mlp2\n",
    "        x = self.mlp2(x) # sxs: bxdxsxs\n",
    "        avgpooled_x2 = self.avgpool2(x) # 1x1: bxdx1x1\n",
    "        x = x.view(x.size(0), x.size(1), -1) # bxdxs^2\n",
    "        avgpooled_x2 = avgpooled_x2.view(avgpooled_x2.size(0), -1) # bxd\n",
    "        # 返回三个值 分别为原始mlp head/经过dense head后的mlp head/经过avgpool head后的mlp head\n",
    "        return [avgpooled_x, x, avgpooled_x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siyi/miniconda3/envs/detection/lib/python3.8/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/siyi/miniconda3/envs/detection/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "base_encoder = models.__dict__[\"resnet50\"]\n",
    "model = DenseCL(base_encoder, mlp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(x, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1, o2 = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 49])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_b = model.encoderk_features(x)\n",
    "# mlp层输出\n",
    "k, k_grid, k2 = model.encoder_k[1](k_b)  # keys: NxC; NxCxS^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 49])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_b.shape[-1]*k_b.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpooled_x = model.encoder_k[1].avgpool(k_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpooled_x = model.encoder_k[1].mlp(avgpooled_x.view(avgpooled_x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.encoder_k[1].mlp2(k_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpooled_x2 = model.encoder_k[1].avgpool2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(x.size(0), x.size(1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpooled_x2 = avgpooled_x2.view(avgpooled_x2.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 49])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_q = model.get_backbone_features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpooled_x, x, avgpooled_x2 = model.encoder_q[1](x_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_q_view = x_q.view(x_q.size(0), x_q.size(1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpooled_x = model.encoder_q[1].mlp(avgpooled_x.view(avgpooled_x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_b = x_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_b = q_b.view(q_b.size(0), q_b.size(1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_b = nn.functinal.normalize(q_b, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "low_dim = 128\n",
    "spatial_dim = 49\n",
    "features_dense = torch.zeros(5, low_dim, spatial_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_feat = torch.rand((1, 128, 49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dense[0] = dense_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5134, 0.4571, 0.6345,  ..., 0.3173, 0.2186, 0.9295],\n",
       "        [0.2037, 0.0660, 0.5016,  ..., 0.0811, 0.9607, 0.1195],\n",
       "        [0.0916, 0.8178, 0.0036,  ..., 0.6055, 0.6242, 0.3834],\n",
       "        ...,\n",
       "        [0.5399, 0.8379, 0.4313,  ..., 0.6114, 0.9327, 0.3372],\n",
       "        [0.6850, 0.2311, 0.3019,  ..., 0.1936, 0.5848, 0.8375],\n",
       "        [0.3109, 0.7516, 0.4075,  ..., 0.8306, 0.4921, 0.9704]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dense[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
