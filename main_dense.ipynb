{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import builtins\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "import pcl.loader\n",
    "import pcl.dense_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    start_epoch = 0\n",
    "    epochs = 100\n",
    "    warmup_epoch = 5\n",
    "    num_cluster = [10, 20, 30]\n",
    "    low_dim = 128\n",
    "    gpu = 0\n",
    "    exp_dir = './test'\n",
    "    num_cluster_global = \"10,20,30\"\n",
    "    num_cluster_dense = \"5,15,20\"\n",
    "    arch = \"resnet50\"\n",
    "    pcl_r = 20\n",
    "    moco_m = 0.999\n",
    "    temperature = 0.2\n",
    "    mlp = True\n",
    "    weight_decay = 1e-4\n",
    "    lr = 0.03\n",
    "    momentum = 0.999\n",
    "    \n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_cluster_global = args.num_cluster_global.split(',')\n",
    "args.num_cluster_dense = args.num_cluster_dense.split(',')\n",
    "\n",
    "os.makedirs(args.exp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pcl.dense_builder.DenseCL(\n",
    "    models.__dict__[\"resnet50\"],\n",
    "    head=None,\n",
    "    dim=args.low_dim,\n",
    "    r=args.pcl_r, \n",
    "    m=args.moco_m, \n",
    "    loss_lambda=args.temperature, \n",
    "    mlp=args.mlp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "    \n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data = '/home/siyi/DefectDetection/CL_for_Real/PCLv1/data/hg'\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.aug_plus = True\n",
    "if args.aug_plus:\n",
    "    # MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
    "    augmentation = [\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "        transforms.RandomApply(\n",
    "            [transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8  # not strengthened\n",
    "        ),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomApply([pcl.loader.GaussianBlur([0.1, 2.0])], p=0.5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    "else:\n",
    "    # MoCo v1's aug: same as InstDisc https://arxiv.org/abs/1805.01978\n",
    "    augmentation = [\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    "\n",
    "# center-crop augmentation\n",
    "eval_augmentation = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = pcl.loader.ImageFolderInstance(\n",
    "    traindir, pcl.loader.TwoCropsTransform(transforms.Compose(augmentation))\n",
    ")\n",
    "eval_dataset = pcl.loader.ImageFolderInstance(traindir, eval_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = None\n",
    "eval_sampler = None\n",
    "args.batch_size = 32\n",
    "args.workers = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=(train_sampler is None),\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# dataloader for center-cropped images, use larger batch size to increase speed\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=args.batch_size * 5,\n",
    "    shuffle=False,\n",
    "    sampler=eval_sampler,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result = {\"cluster_result_dense\": None, \"cluster_result_global\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
    "data_time = AverageMeter(\"Data\", \":6.3f\")\n",
    "losses = AverageMeter(\"Loss\", \":.4e\")\n",
    "acc_inst = AverageMeter(\"Acc@Inst\", \":6.2f\")\n",
    "acc_proto_global = AverageMeter(\"Acc@Proto_global\", \":6.2f\")\n",
    "acc_proto_dense = AverageMeter(\"Acc@Proto_dense\", \":6.2f\")\n",
    "\n",
    "progress = ProgressMeter(\n",
    "    len(train_loader),\n",
    "    [batch_time, data_time, losses, acc_inst, acc_proto_global, acc_proto_dense],\n",
    "    prefix=\"Epoch: [{}]\".format(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, index = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.forward(im_q=images[0], im_k=images[1],\n",
    "#                       cluster_global=cluster_result[\"cluster_result_global\"],\n",
    "#                       cluster_dense=cluster_result[\"cluster_result_dense\"],\n",
    "#                       index=index)\n",
    "\n",
    "im_q=images[0]\n",
    "im_k=images[1]\n",
    "cluster_global=None\n",
    "cluster_dense=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_q = im_q.contiguous()\n",
    "im_k = im_k.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_b = model.encoderq_features(im_q)  # backbone features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, q_grid, q2 = model.encoder_q[1](q_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_b = q_b.view(q_b.size(0), q_b.size(1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = nn.functional.normalize(q, dim=1)   # global\n",
    "q2 = nn.functional.normalize(q2, dim=1) # dense\n",
    "q_grid = nn.functional.normalize(q_grid, dim=1)\n",
    "q_b = nn.functional.normalize(q_b, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._momentum_update_key_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_b = model.encoderk_features(im_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, k_grid, k2 = model.encoder_k[1](k_b)  # keys: NxC; NxCxS^2\n",
    "k_b = k_b.view(k_b.size(0), k_b.size(1), -1)\n",
    "\n",
    "k = nn.functional.normalize(k, dim=1)   # global\n",
    "k2 = nn.functional.normalize(k2, dim=1)  # dense\n",
    "k_grid = nn.functional.normalize(k_grid, dim=1)\n",
    "k_b = nn.functional.normalize(k_b, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)  # 正样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_neg = torch.einsum('nc,ck->nk', [q, model.queue.clone().detach()]) # 负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选取r个原型副样本\n",
    "l_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_sim_matrix = torch.matmul(q_b.permute(0, 2, 1), k_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "densecl_sim_q = backbone_sim_matrix.max(dim=2)[1]   # NxS^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pos_dense = densecl_sim_q.view(-1).unsqueeze(-1)  # NS^2x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_grid = q_grid.permute(0, 2, 1)\n",
    "q_grid = q_grid.reshape(-1, q_grid.size(2))\n",
    "l_neg_dense = torch.einsum('nc,ck->nk', [q_grid,model.queue2.clone().detach()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_global = torch.cat([l_pos, l_neg], dim=1)  # Nx(1+K)\n",
    "logits_dense = torch.cat([l_pos_dense, l_neg_dense], dim=1)\n",
    "# apply temperature\n",
    "logits_global /= 0.2\n",
    "logits_dense /= 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_global = torch.zeros(logits_global.shape[0], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dense = torch.zeros(logits_dense.shape[0], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1568, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_pos_dense.shape   # 一个正样本 pcl_r个负原型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1568, 21])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
